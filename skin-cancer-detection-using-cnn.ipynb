{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this code, I build a CNN to predict whether a skin cancer is malignant or benign. Data is RGB images, published by ISIC. Following shows the steps I took in this project: <br>\n\n1- Import libraries <br>\n2- Load a small set of data to estimate Mean and std, needed for Normalization step further in the process <br>\n3- Load data with appropriate transformations including data augmentation <br>\n4- Visual inspection of data samples <br>\n5- Build a CNN <br>\n6- Train/evaluate <br>\n7- Visualize model performance <br>\n8- Save the model <br>","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\n\nimport cv2 as cv\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\ntrain_path = '/kaggle/input/skin-cancer-malignant-vs-benign/train'\ntest_path = '/kaggle/input/skin-cancer-malignant-vs-benign/test'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T13:30:27.851841Z","iopub.execute_input":"2023-08-02T13:30:27.852755Z","iopub.status.idle":"2023-08-02T13:30:29.873708Z","shell.execute_reply.started":"2023-08-02T13:30:27.852718Z","shell.execute_reply":"2023-08-02T13:30:29.872737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find mean and std of data","metadata":{}},{"cell_type":"code","source":"train_data = torchvision.datasets.ImageFolder(train_path, transform=T.Compose([T.Resize(32)]))\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=None, shuffle=True)\n\nN_samples = 100\n\nsums = 0\nsum_sq = 0\nfor counter, (image, _) in enumerate(train_loader):\n    if counter < N_samples:\n        img = T.ToTensor()(image)\n        sums += torch.sum(img.reshape(3, -1), dim=1)\n        sum_sq += torch.sum(img.reshape(3, -1) ** 2, dim=1)\n    else:\n        break\n\nN = N_samples * torch.numel(img)\nmean = sums / N\nstd = torch.sqrt(sum_sq / N - mean ** 2)\n\nprint(f'Mean:{mean} std:{std}')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:30:31.309264Z","iopub.execute_input":"2023-08-02T13:30:31.310660Z","iopub.status.idle":"2023-08-02T13:30:33.394470Z","shell.execute_reply.started":"2023-08-02T13:30:31.310617Z","shell.execute_reply":"2023-08-02T13:30:33.393485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create data loaders","metadata":{}},{"cell_type":"code","source":"new_size = (256, 256)\nbatch_size = 32\n\n# ----- train data\ntrain_transforms = T.Compose([\n    T.Resize(new_size),\n    T.ToTensor(),\n    T.RandomErasing(p=0.5, scale=(0.02, 0.10), ratio=(0.25, 4)),\n    T.Normalize(mean=mean, std=std)\n])\n\ntrain_data = torchvision.datasets.ImageFolder(train_path, transform=train_transforms)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\nprint('Train data loaded!')\n\n\n\n# ----- test data\ntest_transforms = T.Compose([\n    T.Resize(new_size),\n    T.ToTensor(),\n    T.Normalize(mean=mean, std=std)\n])\n\ntest_data = torchvision.datasets.ImageFolder(test_path, transform=test_transforms)\ntest_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\nprint('Test data loaded!')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:30:37.635462Z","iopub.execute_input":"2023-08-02T13:30:37.635819Z","iopub.status.idle":"2023-08-02T13:30:37.981730Z","shell.execute_reply.started":"2023-08-02T13:30:37.635788Z","shell.execute_reply":"2023-08-02T13:30:37.980786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot some samples","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(4,8, figsize=(18,10))\nax = ax.ravel()\n\nfor counter, ind in enumerate( np.random.randint(0,len(train_data), 32) ):\n    img, target = train_data[ind]\n    img = torch.permute(img, [1, 2, 0])\n    ax[counter].imshow(img)\n    label = [key for key, val in train_data.class_to_idx.items() if val == target][0]\n    ax[counter].set_title(label)\n    ax[counter].axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:30:40.245481Z","iopub.execute_input":"2023-08-02T13:30:40.247288Z","iopub.status.idle":"2023-08-02T13:30:43.800956Z","shell.execute_reply.started":"2023-08-02T13:30:40.247243Z","shell.execute_reply":"2023-08-02T13:30:43.800042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the CNN model","metadata":{}},{"cell_type":"code","source":"model = nn.Sequential(\n    nn.Conv2d(3, 16, kernel_size=3, stride=1, padding='same'),\n    nn.BatchNorm2d(16),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same'),\n    nn.BatchNorm2d(32),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding='same'),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding='same'),\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding='same'),\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n\n    nn.Flatten(),\n    nn.Linear(256 * 8 * 8, 128),\n    nn.ReLU(),\n    nn.Linear(128, 8),\n    nn.ReLU(),\n    nn.Linear(8, 2)\n)\n\ncriterion = nn.CrossEntropyLoss()\n\nlearning_rate = 1e-5\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.5, patience=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:58:11.790447Z","iopub.execute_input":"2023-08-02T13:58:11.790817Z","iopub.status.idle":"2023-08-02T13:58:11.823179Z","shell.execute_reply.started":"2023-08-02T13:58:11.790779Z","shell.execute_reply":"2023-08-02T13:58:11.822245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"n_epochs = 20\n\nmodel.to(device)\n\ntrain_loss_all = []\ntest_loss_all = []\nAccuracy_all = []\nlr_all = []\n\nfor epoch in range(n_epochs):\n    model.train()\n    \n    train_loss = 0\n    num_correct = 0\n    num_total = 0\n    for batch_ind, batch in enumerate(train_loader):\n        images = batch[0].to(device)\n        targets = batch[1].to(device)\n        \n        optimizer.zero_grad()\n        scores = model(images)\n        loss = criterion(scores, targets)\n        loss.backward()\n        optimizer.step()\n        \n        _, predicted = torch.max(scores, 1)\n        num_correct += (predicted == targets).sum().item()\n        num_total += targets.size(0)\n\n        train_loss += loss.item()\n        \n    train_loss = train_loss / len(train_loader)\n    Accuracy_train = num_correct / num_total * 100        \n        \n    with torch.no_grad():\n        model.eval()\n        \n        test_loss = 0\n        num_correct = 0\n        num_total = 0\n        for images, targets in test_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            scores = model(images)\n            _, predicted = torch.max(scores, 1)\n            \n            loss = criterion(scores, targets)\n            test_loss += loss.item()\n            \n            num_correct += (predicted == targets).sum().item()\n            num_total += targets.size(0)\n        \n        test_loss = test_loss / len(test_loader)\n        Accuracy_test = num_correct / num_total * 100\n        \n    lr = optimizer.state_dict()['param_groups'][0]['lr']\n    lr_all.append(lr)\n    scheduler.step(test_loss)\n    \n    Accuracy_all.append( (Accuracy_train, Accuracy_test) )\n    train_loss_all.append( train_loss )\n    test_loss_all.append( test_loss )\n    print(f'[{epoch+1}/{n_epochs}]:\\\n    Train_error={train_loss:.2f} Test_error={test_loss:.2f} ----------------------\\\n    Train_Acc={Accuracy_train:0.1f} Test_Acc={Accuracy_test:0.1f} ----------------------\\\n    Lr:{lr:.8f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:58:12.702608Z","iopub.execute_input":"2023-08-02T13:58:12.702972Z","iopub.status.idle":"2023-08-02T14:03:38.772506Z","shell.execute_reply.started":"2023-08-02T13:58:12.702939Z","shell.execute_reply":"2023-08-02T14:03:38.771508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(12,3))\nax[0].plot(np.array(train_loss_all), label='Train_loss')\nax[0].plot(np.array(test_loss_all), label='Test_loss')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Losses')\n\nax[1].plot(np.array(Accuracy_all)[:,0], label='Train_accuracy')\nax[1].plot(np.array(Accuracy_all)[:,1], label='Test_accuracy')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/trained_model')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T23:24:07.891995Z","iopub.execute_input":"2023-07-31T23:24:07.892585Z","iopub.status.idle":"2023-07-31T23:24:07.934722Z","shell.execute_reply.started":"2023-07-31T23:24:07.892539Z","shell.execute_reply":"2023-07-31T23:24:07.933718Z"},"trusted":true},"execution_count":null,"outputs":[]}]}